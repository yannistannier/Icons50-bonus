{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = []\n",
    "for image in glob.glob(os.path.join(\"/SSD/DGFIP_2/Icons-50/\", \"*\", \"*.png\")):\n",
    "    \n",
    "    info = os.path.basename(image).split(\"_\")\n",
    "    company = info[0]\n",
    "    style = \"_\".join(info[2:])[:-4]\n",
    "    \n",
    "    if company == \"microsoft\":\n",
    "        train_test = \"test\"\n",
    "    else:\n",
    "        train_test = \"train\"\n",
    "    csv.append({\"name\": image, \"label_name\": image.split(\"/\")[-2], \"type\": train_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(csv)\n",
    "train = df[df[\"type\"] == \"train\"]\n",
    "test = df[df[\"type\"] == \"test\"]\n",
    "\n",
    "class_indices = { v:k for k, v in enumerate(pd.Categorical(train[\"label_name\"]).categories) }\n",
    "\n",
    "train[\"label\"] = [class_indices[x] for x in train[\"label_name\"]]\n",
    "test[\"label\"] = [class_indices[x] for x in test[\"label_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train_microsoft.csv\", index=False)\n",
    "test.to_csv(\"test_microsoft.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gnd = [ class_indices[x] for x in train[\"label_name\"]]\n",
    "test_gnd = [ class_indices[x] for x in test[\"label_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmix = pd.read_csv(\"data_augmix.csv\")\n",
    "train = train.append(\n",
    "    data_augmix[data_augmix[\"source\"].isin(train[\"name\"])]\n",
    ")\n",
    "\n",
    "train[\"label\"] = [class_indices[x] for x in train[\"label_name\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) Retrieval Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pool = np.concatenate((\n",
    "        np.load(\"./features/MICROSOFT_v4_32_train.npy\"),\n",
    "        np.load(\"./SSD/features/MICROSOFT_v4_64_train.npy\")\n",
    "    ), 1)\n",
    "\n",
    "feature_query = np.concatenate((\n",
    "        np.load(\"./features/MICROSOFT_v4_32_test.npy\"),\n",
    "        np.load(\"./features/MICROSOFT_v4_64_test.npy\")\n",
    "    ), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score macro: 0.9208836911498736\n",
      "F1_score macro: 0.9321203707245164\n",
      "Accuracy:  0.9335968379446641\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatIP(feature_query.shape[1])\n",
    "index.add(normalize(feature_pool))\n",
    "D, I = index.search(normalize(feature_query), 200)\n",
    "\n",
    "preds = []\n",
    "for k, (i, d) in enumerate(zip(I, D)):\n",
    "    ii = i[d > 0.3]\n",
    "    labels = [ train_gnd[it] for it in ii[:10] ]\n",
    "    pred = Counter(labels).most_common()[0][0]\n",
    "    preds.append(pred)\n",
    "preds = np.array(preds)\n",
    "\n",
    "print(\"F1_score macro:\", f1_score(test_gnd, preds, average=\"macro\"))\n",
    "print(\"F1_score macro:\", f1_score(test_gnd, preds, average=\"weighted\"))\n",
    "print(\"Accuracy: \", accuracy_score(test_gnd, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
